import tensorflow as tf 
import cv2
import os
import matplotlib.pyplot as plt
import numpy as np

img_array = cv2.imread("Test_dataset/closed_eyes/s0001_00056_0_0_0_0_01.png",cv2.IMREAD_GRAYSCALE)
plt.imshow(img_array,cmap="gray")
img_array.shape

Datadirectory = "test_Dataset/"
classes = ["Closed_Eyes","open_Eyes"]
for category in classes:
  path =os.path.join(Datadirectory,category)
  for img in os.listdir(path):
  img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)
  backtorgb = cv2.cvtColor(img_array,cv2.COLOR_GRAY2RGB)
  plt.imshow(img_array, cmap="gray")
  plt.show()
  break
break

img_size = 224
new_arrays = cv2.resize(backtorgb, (img_size, img_size))
plt.imshow(new_array, cmap="gray")
plt.show() 


training_Data =[]
def create_training_Data():
  for category in Classes:
    path = os.path.jin(Datadirectory, category)
     class_num = Classes.index(category)
     forikmg in os.listdir(path):
      try:
          img_array  = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)
          backtorgb = cv2.cvtColor(img_array,cv2.COLOR_GRAY2RGB)
          new_array = cv2.resize(backtorgb, (img_size, img_size))
          training_Dat.append([new_array,class_num])
       except Excepiton as e:
           pass

create_training_Data()
print(len(training_Data))
import random
random.shuffle(training_Data)

X = []
y = []
for features,label in training_Data:
  X.append(features)
  y.append(label)

X = np.array(X).reshape(-1, img_size, img_size, 3)

X.shape

X=X/2555.0

Y=np.array(y)
import pickle

pickle_out = open("X.pickle","wb")
pickle.dump(X, pickle_out)
pickle_out.close()

pickle_out = open("y.pickle","wb")
pickle.dump(X, pickle_out)
pickle_out.close()

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

model = tf.keras.applications.mobilenet.MobileNet()

model.summary()

base_input = model.layers[0].input
base_output = model.layer[-4].output
Flat_layer= layers.Flatten()(base_output)
final_output = layers.Dense(1)(Flat_layer) ## one node(1/0)
final_output = layers.Activation('signoid')(final_output) 
new_model = keras.Model(inputs = base_input, outputs= final_output)
layerslayerss
new_model.summary()

new_model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
new_model.fit(X,Y, epochs = 1,validation_split=0.1) ## training
new_model.save('my_model.hS')
new_model = tf.keras.models.load_model('my_model_Drosiness.hS')

img_array = cv2.imread('s0012_08255_0_0_1_1_0_02.png', cv2.IMREAD_GRAYSCALE)
backtorgb = cv2.cvtColor(img_array,cv2.COLOR_GRAY2RGB)
new_array= cv2.resize(backtorgb, (img_size,img_size))
X_input = np.array(new_array).reshape(1, img_size, img_size, 3)
X_input.shape
plt.imshow(new_array)
X_input=X_input/255.0
prediction = new_model.predict(X_input)
prediction

img = cv2.imread('sad_women.jpg')
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier(cv2.data.harrcascades +'haarcascade_eye.xml')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
eyes = eye_cascade.detectMultiScale(gray,1.1,4)
for(x, y, w, h) in eyes:
    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascade +'haarcascade_eye.xml')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
eye = eye_cascade.detectMultiScale(gray,1.1,4)
for x,y,w,h in eyes:
    roi_gray = gray[y:y+h, x:x+w]
    roi_color = img[y:y+h, x:x+w]
    eyess = eye_cascade.detectMultiScale(roi_gray)
    if len(eyess) == 0:
       print("eyes are not detected")
    else:
       for (ex,ey,ew,eh) in eyess:
            eyes_roi = roi_color[ey: ey+eh, ex:ex + ew]
plt.imshow(cv2.cvtColor(eyes_roi, cv2.COLOR_BGR2RGB))
eyes_roi.shape

final_image =cv2.resize(eyes_roi, (224,224))
final_image = np.expand_dims(final_image,axis =0)
final_image=final_image/255.0
final_image.shape
new_model.predict(final_image)
import cv2
path = "haarcascade_frontalface_default.xml"
faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
cap = cv2.VideoCapture(1)
if not cap.isOpened():
    cap = cv2.VideoCapture(0)
if not cap.isOpened():
    raise IOError("Cannot open webcam")
while True:
    ret,frame = cap.read()
    eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_eye.xml')
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    eyes = eye_cascade.detectMultiScale(gray,1.1,4)
    for x,y,w,h in eyes:
        roi_gray = gray[y:y+h, x:x+w]
        roi_color = frame[y:y+h, x:x+w]
        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0),2)
        eyess = eye_cascade.detectMultiScale(roi_gray)
        if len(eyess) == 0:
            print("eyes are not detected")  

